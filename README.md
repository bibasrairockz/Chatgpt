# chatgpt  

# GPT Language Model ğŸš€

A simple, PyTorch-based implementation of a **GPT-style language model** trained on character-level data. This project explores the basics of the Transformer architecture and generates text based on input context.

## Features âœ¨
- Transformer architecture with multi-head self-attention.
- Trainable on any character-level dataset.
- Generates coherent text based on input sequences.

## Setup ğŸ”§

1. **Clone the repository**:
    ```bash
    git clone https://github.com/bibasrairockz/chatgpt.git
    cd chatgpt
    ```

2. **Install dependencies**:
    ```bash
    pip install torch
    ```

3. **Prepare your dataset**:  
    Add a text file named `input.txt` for training.

## Training the Model ğŸ‹ï¸

Run the training script:
```bash
python gpt.py

![image](https://github.com/user-attachments/assets/ac4ca37c-4f4a-4e51-80ed-137d2ed0013d)  

  
